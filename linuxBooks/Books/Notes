
nothing in life is free.


Linux is many things to many people.The basics of a Linux system are the kernel, C
library, toolchain, and basic system utilities, such as a login process and shell.A Linux system
can also include a modern X Window System implementation including a full-featured
desktop environment, such as GNOME.Thousands of free and commercial applications
exist for Linux. In this book, when I say Linux I typically mean the Linux kernel.Where it is
ambiguous, I try explicitly to point out whether I am referring to Linux as a full system or
just the kernel proper. Strictly speaking, the term Linux refers only to the kernel.



the operating system is considered the parts of the system
responsible for basic use and administration.This includes the kernel and device drivers,
boot loader, command shell or other user interface, and basic file and system utilities. It is
the stuff you need—not a web browser or music players.The term system, in turn, refers to
the operating system and all the applications running on top of it.


Typical components of a kernel are
interrupt handlers to service interrupt requests, 
a scheduler to share processor time among multiple processes,
a memory management system to manage process address spaces, 
and system services such as networking and interprocess communication.


This includes a protected
memory space and full access to the hardware.This system state and memory space is col-
lectively referred to as kernel-space.


user applications execute in user-space.They
see a subset of the machine’s available resources and can perform certain system functions,
directly access hardware, access memory outside of that allotted them by the kernel, or
otherwise misbehave.When executing kernel code, the system is in kernel-space execut-
ing in kernel mode.When running a regular process, the system is in user-space executing
in user mode.

When an application executes a system call, we say that the kernel is
executing on behalf of the application. Furthermore, the application is said to be executing a
system call in kernel-space, and the kernel is running in process context.This relationship—
that applications call into the kernel via the system call interface—is the fundamental man-
ner in which applications get work done.


In many operating systems, including Linux,
the interrupt handlers do not run in a process context. Instead, they run in a special
interrupt context that is not associated with any process.This special context exists solely to
let an interrupt handler quickly respond to an interrupt, and then exit.


In fact, in Linux, we can
generalize that each processor is doing exactly one of three things at any given moment:

1.In user-space, executing user code in a process
2.In space-in, process context executing, on behalf of a specific process kernel
3.In kernel-space, in interrupt context, not associated with a process, handling an
interrupt.



Linux is a monolithic kernel; that is, the Linux kernel executes in a single address space
entirely in kernel mode. Linux, however, borrows much of the good from microkernels: Linux
boasts a modular design, the capability to preempt itself (called kernel preemption), support
for kernel threads, and the capability to dynamically load separate binaries (kernel modules)
into the kernel image. Conversely, Linux has none of the performance-sapping features that
curse microkernel design: Everything runs in kernel mode, with direct function invocation—
not message passing—the modus of communication. Nonetheless, Linux is modular,
threaded, and the kernel itself is schedulable. Pragmatism wins again.




A handful of notable differences exist between the Linux kernel and classic
Unix systems:
1.Linux supports the dynamic loading of kernel modules.Although the Linux kernel
is monolithic, it can dynamically load and unload kernel code on demand.
2.Linux has symmetrical multiprocessor (SMP) support.Although most commercial
variants of Unix now support SMP, most traditional Unix implementations did not.
3.The Linux kernel is preemptive. Unlike traditional Unix variants, the Linux kernel
can preempt a task even as it executes in the kernel. Of the other commercial Unix
implementations, Solaris and IRIX have preemptive kernels, but most Unix kernels
are not preemptive.
4.Linux takes an interesting approach to thread support: It does not differentiate
between threads and normal processes.To the kernel, all processes are the same—
some just happen to share resources.
5.Linux provides an object-oriented device model with device classes, hot-pluggable
events, and a user-space device filesystem (sysfs).
6.Linux ignores some common Unix features that the kernel developers consider
poorly designed, such as STREAMS, or standards that are impossible to cleanly
implement.
7.Linux is free in every sense of the word.The feature set Linux implements is the
result of the freedom of Linux’s open development model. If a feature is without
merit or poorly thought out, Linux developers are under no obligation to imple-
ment it.To the contrary, Linux has adopted an elitist attitude toward changes: Mod-
ifications must solve a specific real-world problem, derive from a clean design, and
have a solid implementation. Consequently, features of some other modern Unix
variants that are more marketing bullet or one-off requests, such as pageable kernel
memory, have received no consideration.



Configuration options that control the build process are either Booleans or tristates.A
Boolean option is either yes or no. Kernel features, such as CONFIG_PREEMPT , are usually
Booleans.A tristate option is one of yes, no, or module.The module setting represents a con-
figuration option that is set but is to be compiled as a module (that is, a separate dynami-
cally loadable object). In the case of tristates, a yes option explicitly means to compile the
code into the main kernel image and not as a module. Drivers are usually represented by
tristates.

Configuration options can also be strings or integers.These options do not control the
build process but instead specify values that kernel source can access as a preprocessor
macro. For example, a configuration option can specify the size of a statically allocated
array.


The make program provides a feature to split the build process into a number of parallel
jobs. Each of these jobs then runs separately and concurrently, significantly speeding up the
build process on multiprocessing systems. It also improves processor utilization because the
time to build a large source tree includes significant time in I/O wait (time in which the
process is idle waiting for an I/O request to complete).

Using utilities such as the excellent distcc or ccache can also dramatically improve
kernel build time.


After the kernel is built, you need to install it. How it is installed is architecture- and boot
loader-dependent—consult the directions for your boot loader on where to copy the ker-
nel image and how to set it up to boot.Always keep a known-safe kernel or two around in
case your new kernel has problems


Installing modules, thankfully, is automated and architecture-independent. As root,
simply run
% make modules_install


This installs all the compiled modules to their correct home under /lib/modules .
The build process also creates the file System.map in the root of the kernel source tree.
It contains a symbol lookup table, mapping kernel symbols to their start addresses.This is
used during debugging to translate memory addresses to function and variable names.



A Beast of a Different Nature
The Linux kernel has several unique attributes as compared to a normal user-space appli-
cation.Although these differences do not necessarily make developing kernel code harder
than developing user-space code, they certainly make doing so different.A Beast of a Different Nature
These characteristics make the kernel a beast of a different nature. Some of the usual
rules are bent; other rules are entirely new.Although some of the differences are obvious
(we all know the kernel can do anything it wants), others are not so obvious.The most
important of these differences are:-
1.The kernel has access to neither the C library nor the standard C headers.
2.The kernel is coded in GNU C.
3.The kernel lacks the memory protection afforded to user-space.
4.The kernel cannot easily execute floating-point operations.
5.The kernel has a small per-process fixed-size stack.
6.Because the kernel has asynchronous interrupts, is preemptive, and supports SMP,
synchronization and concurrency are major concerns within the kernel.
7.Portability is important.



printk("Hello world! A string '%s' and an integer '%d'\n", str, i);
One notable difference between printf() and printk() is that printk() enables you
to specify a priority flag.This flag is used by syslogd to decide where to display kernel
messages. Here is an example of these priorities:
printk(KERN_ERR "this is an error!\n");
Note there is no comma between KERN_ERR and the printed message.This is inten-
tional; the priority flag is a preprocessor-define representing a string literal, which is con-
catenated onto the printed message during compilation.




Perhaps sur-prisingly, the kernel is not programmed in strict ANSI C. Instead, where applicable, the
kernel developers make use of various language extensions available in gcc (the GNU
Compiler Collection, which contains the C compiler used to compile the kernel and
most everything else written in C on a Linux system).
The kernel developers use both ISO C99 and GNU C extensions to the C language.
These changes wed the Linux kernel to gcc, although recently one other compiler, the
Intel C compiler, has sufficiently supported enough gcc features that it, too, can compile
the Linux kernel.The earliest supported gcc version is 3.2; gcc version 4.4 or later is rec-
ommended.The ISO C99 extensions that the kernel uses are nothing special and, because
C99 is an official revision of the C language, are slowly cropping up in a lot of other
code.The more unfamiliar deviations from standard ANSI C are those provided by GNU
C.

Inline Functions
Both C99 and GNU C support inline functions.An inline function is, as its name suggests,
inserted inline into each function call site.This eliminates the overhead of function invo-
cation and return (register saving and restore) and allows for potentially greater optimiza-
tion as the compiler can optimize both the caller and the called function as one.As a
downside (nothing in life is free), code size increases because the contents of the function
are copied into all the callers, which increases memory consumption and instruction
cache footprint. Kernel developers use inline functions for small time-critical functions.

An inline function is declared when the keywords static and inline are used as part
of the function definition. For example
static inline void wolf(unsigned long tail_size)
The function declaration must precede any usage, or else the compiler cannot make
the function inline. Common practice is to place inline functions in header files. Because
they are marked static , an exported function is not created. If an inline function is used
by only one file, it can instead be placed toward the top of just that file.
In the kernel, using inline functions is preferred over complicated macros for reasons
of type safety and readability.

Inline Assembly
The gcc C compiler enables the embedding of assembly instructions in otherwise normal
C functions.This feature, of course, is used in only those parts of the kernel that are
unique to a given system architecture.
The asm() compiler directive is used to inline assembly code. For example, this inline
assembly directive executes the x86 processor’s rdtsc instruction, which returns the value
of the timestamp ( tsc ) register:
unsigned int low, high;
asm volatile("rdtsc" : "=a" (low), "=d" (high));
/* low and high now contain the lower and upper 32-bits of the 64-bit tsc */
The Linux kernel is written in a mixture of C and assembly, with assembly relegated
to low-level architecture and fast path code.The vast majority of kernel code is pro-
grammed in straight C.



Branch Annotation
The gcc C compiler has a built-in directive that optimizes conditional branches as either
very likely taken or very unlikely taken.The compiler uses the directive to appropriately
optimize the branch.The kernel wraps the directive in easy-to-use macros, likely() and
unlikely() .
For example, consider an if statement such as the following:
if (error) {
/* ... */
}
To mark this branch as very unlikely taken (that is, likely not taken):
/* we predict 'error' is nearly always zero ... */
if (unlikely(error)) {
/* ... */
}
Conversely, to mark a branch as very likely taken:
/* we predict 'success' is nearly always nonzero ... */
if (likely(success)) {
/* ... */
}
You should only use these directives when the branch direction is overwhelmingly
known a priori or when you want to optimize a specific case at the cost of the other case.
This is an important point:These directives result in a performance boost when the
branch is correctly marked, but a performance loss when the branch is mismarked.A
common usage, as shown in these examples, for unlikely() and likely() is error con-
ditions.As you might expect, unlikely() finds much more use in the kernel because if
statements tend to indicate a special case.

No Memory Protection
When a user-space application attempts an illegal memory access, the kernel can trap the
error, send the SIGSEGV signal, and kill the process. If the kernel attempts an illegal mem-
ory access, however, the results are less controlled. (After all, who is going to look after the
kernel?) Memory violations in the kernel result in an oops, which is a major kernel error.
It should go without saying that you must not illegally access memory, such as dereferenc-
ing a NULL pointer—but within the kernel, the stakes are much higher!
Additionally, kernel memory is not pageable.Therefore, every byte of memory you
consume is one less byte of available physical memory. Keep that in mind the next time
you need to add one more feature to the kernel!


No (Easy) Use of Floating Point
When a user-space process uses floating-point instructions, the kernel manages the transi-
tion from integer to floating point mode.What the kernel has to do when using floating-
point instructions varies by architecture, but the kernel normally catches a trap and then
initiates the transition from integer to floating point mode.
Unlike user-space, the kernel does not have the luxury of seamless support for floating
point because it cannot easily trap itself. Using a floating point inside the kernel requires
manually saving and restoring the floating point registers, among other possible chores.
The short answer is: Don’t do it! Except in the rare cases, no floating-point operations are
in the kernel.


Small, Fixed-Size Stack
User-space can get away with statically allocating many variables on the stack, including
huge structures and thousand-element arrays.This behavior is legal because user-space has
a large stack that can dynamically grow. (Developers on older, less advanced operating
systems—say, DOS—might recall a time when even user-space had a fixed-sized stack.)Conclusion
The kernel stack is neither large nor dynamic; it is small and fixed in size.The exact
size of the kernel’s stack varies by architecture. On x86, the stack size is configurable at
compile-time and can be either 4KB or 8KB. Historically, the kernel stack is two pages,
which generally implies that it is 8KB on 32-bit architectures and 16KB on 64-bit archi-
tectures—this size is fixed and absolute. Each process receives its own stack.



Synchronization and Concurrency
The kernel is susceptible to race conditions. Unlike a single-threaded user-space applica-
tion, a number of properties of the kernel allow for concurrent access of shared resources
and thus require synchronization to prevent races. Specifically
1.Linux is a preemptive multitasking operating system. Processes are scheduled and
rescheduled at the whim of the kernel’s process scheduler.The kernel must syn-
chronize between these tasks.
2.Linux supports symmetrical multiprocessing (SMP).Therefore, without proper pro-
tection, kernel code executing simultaneously on two or more processors can con-
currently access the same resource.
3.Interrupts occur asynchronously with respect to the currently executing code.
Therefore, without proper protection, an interrupt can occur in the midst of access-
ing a resource, and the interrupt handler can then access the same resource.
4.The Linux kernel is preemptive.Therefore, without protection, kernel code can be
preempted in favor of different code that then accesses the same resource.


Importance of Portability
Although user-space applications do not have to aim for portability, Linux is a portable
operating system and should remain one.This means that architecture-independent C
code must correctly compile and run on a wide range of systems, and that architecture-
dependent code must be properly segregated in system-specific directories in the kernel
source tree.
A handful of rules—such as remain endian neutral, be 64-bit clean, do not assume the
word or page size, and so on—go a long way.





struct task_struct {
	volatile long state;	/* -1 unrunnable, 0 runnable, >0 stopped */
	void *stack;
	atomic_t usage;
	unsigned int flags;	/* per process flags, defined below */
	unsigned int ptrace;

#ifdef CONFIG_SMP
	struct llist_node wake_entry;
	int on_cpu;
	struct task_struct *last_wakee;
	unsigned long wakee_flips;
	unsigned long wakee_flip_decay_ts;

	int wake_cpu;
#endif
	int on_rq;

	int prio, static_prio, normal_prio;
	unsigned int rt_priority;
	const struct sched_class *sched_class;
	struct sched_entity se;
	struct sched_rt_entity rt;
#ifdef CONFIG_CGROUP_SCHED
	struct task_group *sched_task_group;
#endif
	struct sched_dl_entity dl;

#ifdef CONFIG_PREEMPT_NOTIFIERS
	/* list of struct preempt_notifier: */
	struct hlist_head preempt_notifiers;
#endif

#ifdef CONFIG_BLK_DEV_IO_TRACE
	unsigned int btrace_seq;
#endif

	unsigned int policy;
	int nr_cpus_allowed;
	cpumask_t cpus_allowed;

#ifdef CONFIG_PREEMPT_RCU
	int rcu_read_lock_nesting;
	union rcu_special rcu_read_unlock_special;
	struct list_head rcu_node_entry;
#endif /* #ifdef CONFIG_PREEMPT_RCU */
#ifdef CONFIG_PREEMPT_RCU
	struct rcu_node *rcu_blocked_node;
#endif /* #ifdef CONFIG_PREEMPT_RCU */
#ifdef CONFIG_TASKS_RCU
	unsigned long rcu_tasks_nvcsw;
	bool rcu_tasks_holdout;
	struct list_head rcu_tasks_holdout_list;
	int rcu_tasks_idle_cpu;
#endif /* #ifdef CONFIG_TASKS_RCU */

#if defined(CONFIG_SCHEDSTATS) || defined(CONFIG_TASK_DELAY_ACCT)
	struct sched_info sched_info;
#endif

	struct list_head tasks;
#ifdef CONFIG_SMP
	struct plist_node pushable_tasks;
	struct rb_node pushable_dl_tasks;
#endif

	struct mm_struct *mm, *active_mm;
#ifdef CONFIG_COMPAT_BRK
	unsigned brk_randomized:1;
#endif
	/* per-thread vma caching */
	u32 vmacache_seqnum;
	struct vm_area_struct *vmacache[VMACACHE_SIZE];
#if defined(SPLIT_RSS_COUNTING)
	struct task_rss_stat	rss_stat;
#endif
/* task state */
	int exit_state;
	int exit_code, exit_signal;
	int pdeath_signal;  /*  The signal sent when the parent dies  */
	unsigned int jobctl;	/* JOBCTL_*, siglock protected */

	/* Used for emulating ABI behavior of previous Linux versions */
	unsigned int personality;

	unsigned in_execve:1;	/* Tell the LSMs that the process is doing an
				 * execve */
	unsigned in_iowait:1;

	/* Revert to default priority/policy when forking */
	unsigned sched_reset_on_fork:1;
	unsigned sched_contributes_to_load:1;

#ifdef CONFIG_MEMCG_KMEM
	unsigned memcg_kmem_skip_account:1;
#endif

	unsigned long atomic_flags; /* Flags needing atomic access. */

	pid_t pid;
	pid_t tgid;

#ifdef CONFIG_CC_STACKPROTECTOR
	/* Canary value for the -fstack-protector gcc feature */
	unsigned long stack_canary;
#endif
	/*
	 * pointers to (original) parent process, youngest child, younger sibling,
	 * older sibling, respectively.  (p->father can be replaced with
	 * p->real_parent->pid)
	 */
	struct task_struct __rcu *real_parent; /* real parent process */
	struct task_struct __rcu *parent; /* recipient of SIGCHLD, wait4() reports */
	/*
	 * children/sibling forms the list of my natural children
	 */
	struct list_head children;	/* list of my children */
	struct list_head sibling;	/* linkage in my parent's children list */
	struct task_struct *group_leader;	/* threadgroup leader */

	/*
	 * ptraced is the list of tasks this task is using ptrace on.
	 * This includes both natural children and PTRACE_ATTACH targets.
	 * p->ptrace_entry is p's link on the p->parent->ptraced list.
	 */
	struct list_head ptraced;
	struct list_head ptrace_entry;

	/* PID/PID hash table linkage. */
	struct pid_link pids[PIDTYPE_MAX];
	struct list_head thread_group;
	struct list_head thread_node;

	struct completion *vfork_done;		/* for vfork() */
	int __user *set_child_tid;		/* CLONE_CHILD_SETTID */
	int __user *clear_child_tid;		/* CLONE_CHILD_CLEARTID */

	cputime_t utime, stime, utimescaled, stimescaled;
	cputime_t gtime;
#ifndef CONFIG_VIRT_CPU_ACCOUNTING_NATIVE
	struct cputime prev_cputime;
#endif
#ifdef CONFIG_VIRT_CPU_ACCOUNTING_GEN
	seqlock_t vtime_seqlock;
	unsigned long long vtime_snap;
	enum {
		VTIME_SLEEPING = 0,
		VTIME_USER,
		VTIME_SYS,
	} vtime_snap_whence;
#endif
	unsigned long nvcsw, nivcsw; /* context switch counts */
	u64 start_time;		/* monotonic time in nsec */
	u64 real_start_time;	/* boot based time in nsec */
/* mm fault and swap info: this can arguably be seen as either mm-specific or thread-specific */
	unsigned long min_flt, maj_flt;

	struct task_cputime cputime_expires;
	struct list_head cpu_timers[3];

/* process credentials */
	const struct cred __rcu *real_cred; /* objective and real subjective task
					 * credentials (COW) */
	const struct cred __rcu *cred;	/* effective (overridable) subjective task
					 * credentials (COW) */
	char comm[TASK_COMM_LEN]; /* executable name excluding path
				     - access with [gs]et_task_comm (which lock
				       it with task_lock())
				     - initialized normally by setup_new_exec */
/* file system info */
	int link_count, total_link_count;
#ifdef CONFIG_SYSVIPC
/* ipc stuff */
	struct sysv_sem sysvsem;
	struct sysv_shm sysvshm;
#endif
#ifdef CONFIG_DETECT_HUNG_TASK
/* hung task detection */
	unsigned long last_switch_count;
#endif
/* CPU-specific state of this task */
	struct thread_struct thread;
/* filesystem information */
	struct fs_struct *fs;
/* open file information */
	struct files_struct *files;
/* namespaces */
	struct nsproxy *nsproxy;
/* signal handlers */
	struct signal_struct *signal;
	struct sighand_struct *sighand;

	sigset_t blocked, real_blocked;
	sigset_t saved_sigmask;	/* restored if set_restore_sigmask() was used */
	struct sigpending pending;

	unsigned long sas_ss_sp;
	size_t sas_ss_size;
	int (*notifier)(void *priv);
	void *notifier_data;
	sigset_t *notifier_mask;
	struct callback_head *task_works;

	struct audit_context *audit_context;
#ifdef CONFIG_AUDITSYSCALL
	kuid_t loginuid;
	unsigned int sessionid;
#endif
	struct seccomp seccomp;

/* Thread group tracking */
   	u32 parent_exec_id;
   	u32 self_exec_id;
/* Protection of (de-)allocation: mm, files, fs, tty, keyrings, mems_allowed,
 * mempolicy */
	spinlock_t alloc_lock;

	/* Protection of the PI data structures: */
	raw_spinlock_t pi_lock;

#ifdef CONFIG_RT_MUTEXES
	/* PI waiters blocked on a rt_mutex held by this task */
	struct rb_root pi_waiters;
	struct rb_node *pi_waiters_leftmost;
	/* Deadlock detection and priority inheritance handling */
	struct rt_mutex_waiter *pi_blocked_on;
#endif

#ifdef CONFIG_DEBUG_MUTEXES
	/* mutex deadlock detection */
	struct mutex_waiter *blocked_on;
#endif
#ifdef CONFIG_TRACE_IRQFLAGS
	unsigned int irq_events;
	unsigned long hardirq_enable_ip;
	unsigned long hardirq_disable_ip;
	unsigned int hardirq_enable_event;
	unsigned int hardirq_disable_event;
	int hardirqs_enabled;
	int hardirq_context;
	unsigned long softirq_disable_ip;
	unsigned long softirq_enable_ip;
	unsigned int softirq_disable_event;
	unsigned int softirq_enable_event;
	int softirqs_enabled;
	int softirq_context;
#endif
#ifdef CONFIG_LOCKDEP
# define MAX_LOCK_DEPTH 48UL
	u64 curr_chain_key;
	int lockdep_depth;
	unsigned int lockdep_recursion;
	struct held_lock held_locks[MAX_LOCK_DEPTH];
	gfp_t lockdep_reclaim_gfp;
#endif

/* journalling filesystem info */
	void *journal_info;

/* stacked block device info */
	struct bio_list *bio_list;

#ifdef CONFIG_BLOCK
/* stack plugging */
	struct blk_plug *plug;
#endif

/* VM state */
	struct reclaim_state *reclaim_state;

	struct backing_dev_info *backing_dev_info;

	struct io_context *io_context;

	unsigned long ptrace_message;
	siginfo_t *last_siginfo; /* For ptrace use.  */
	struct task_io_accounting ioac;
#if defined(CONFIG_TASK_XACCT)
	u64 acct_rss_mem1;	/* accumulated rss usage */
	u64 acct_vm_mem1;	/* accumulated virtual memory usage */
	cputime_t acct_timexpd;	/* stime + utime since last update */
#endif
#ifdef CONFIG_CPUSETS
	nodemask_t mems_allowed;	/* Protected by alloc_lock */
	seqcount_t mems_allowed_seq;	/* Seqence no to catch updates */
	int cpuset_mem_spread_rotor;
	int cpuset_slab_spread_rotor;
#endif
#ifdef CONFIG_CGROUPS
	/* Control Group info protected by css_set_lock */
	struct css_set __rcu *cgroups;
	/* cg_list protected by css_set_lock and tsk->alloc_lock */
	struct list_head cg_list;
#endif
#ifdef CONFIG_FUTEX
	struct robust_list_head __user *robust_list;
#ifdef CONFIG_COMPAT
	struct compat_robust_list_head __user *compat_robust_list;
#endif
	struct list_head pi_state_list;
	struct futex_pi_state *pi_state_cache;
#endif
#ifdef CONFIG_PERF_EVENTS
	struct perf_event_context *perf_event_ctxp[perf_nr_task_contexts];
	struct mutex perf_event_mutex;
	struct list_head perf_event_list;
#endif
#ifdef CONFIG_DEBUG_PREEMPT
	unsigned long preempt_disable_ip;
#endif
#ifdef CONFIG_NUMA
	struct mempolicy *mempolicy;	/* Protected by alloc_lock */
	short il_next;
	short pref_node_fork;
#endif
#ifdef CONFIG_NUMA_BALANCING
	int numa_scan_seq;
	unsigned int numa_scan_period;
	unsigned int numa_scan_period_max;
	int numa_preferred_nid;
	unsigned long numa_migrate_retry;
	u64 node_stamp;			/* migration stamp  */
	u64 last_task_numa_placement;
	u64 last_sum_exec_runtime;
	struct callback_head numa_work;

	struct list_head numa_entry;
	struct numa_group *numa_group;

	/*
	 * numa_faults is an array split into four regions:
	 * faults_memory, faults_cpu, faults_memory_buffer, faults_cpu_buffer
	 * in this precise order.
	 *
	 * faults_memory: Exponential decaying average of faults on a per-node
	 * basis. Scheduling placement decisions are made based on these
	 * counts. The values remain static for the duration of a PTE scan.
	 * faults_cpu: Track the nodes the process was running on when a NUMA
	 * hinting fault was incurred.
	 * faults_memory_buffer and faults_cpu_buffer: Record faults per node
	 * during the current scan window. When the scan completes, the counts
	 * in faults_memory and faults_cpu decay and these values are copied.
	 */
	unsigned long *numa_faults;
	unsigned long total_numa_faults;

	/*
	 * numa_faults_locality tracks if faults recorded during the last
	 * scan window were remote/local. The task scan period is adapted
	 * based on the locality of the faults with different weights
	 * depending on whether they were shared or private faults
	 */
	unsigned long numa_faults_locality[2];

	unsigned long numa_pages_migrated;
#endif /* CONFIG_NUMA_BALANCING */

	struct rcu_head rcu;

	/*
	 * cache last used pipe for splice
	 */
	struct pipe_inode_info *splice_pipe;

	struct page_frag task_frag;

#ifdef	CONFIG_TASK_DELAY_ACCT
	struct task_delay_info *delays;
#endif
#ifdef CONFIG_FAULT_INJECTION
	int make_it_fail;
#endif
	/*
	 * when (nr_dirtied >= nr_dirtied_pause), it's time to call
	 * balance_dirty_pages() for some dirty throttling pause
	 */
	int nr_dirtied;
	int nr_dirtied_pause;
	unsigned long dirty_paused_when; /* start of a write-and-pause period */

#ifdef CONFIG_LATENCYTOP
	int latency_record_count;
	struct latency_record latency_record[LT_SAVECOUNT];
#endif
	/*
	 * time slack values; these are used to round up poll() and
	 * select() etc timeout values. These are in nanoseconds.
	 */
	unsigned long timer_slack_ns;
	unsigned long default_timer_slack_ns;

#ifdef CONFIG_FUNCTION_GRAPH_TRACER
	/* Index of current stored address in ret_stack */
	int curr_ret_stack;
	/* Stack of return addresses for return function tracing */
	struct ftrace_ret_stack	*ret_stack;
	/* time stamp for last schedule */
	unsigned long long ftrace_timestamp;
	/*
	 * Number of functions that haven't been traced
	 * because of depth overrun.
	 */
	atomic_t trace_overrun;
	/* Pause for the tracing */
	atomic_t tracing_graph_pause;
#endif
#ifdef CONFIG_TRACING
	/* state flags for use by tracers */
	unsigned long trace;
	/* bitmask and counter of trace recursion */
	unsigned long trace_recursion;
#endif /* CONFIG_TRACING */
#ifdef CONFIG_MEMCG
	struct memcg_oom_info {
		struct mem_cgroup *memcg;
		gfp_t gfp_mask;
		int order;
		unsigned int may_oom:1;
	} memcg_oom;
#endif
#ifdef CONFIG_UPROBES
	struct uprobe_task *utask;
#endif
#if defined(CONFIG_BCACHE) || defined(CONFIG_BCACHE_MODULE)
	unsigned int	sequential_io;
	unsigned int	sequential_io_avg;
#endif
#ifdef CONFIG_DEBUG_ATOMIC_SLEEP
	unsigned long	task_state_change;
#endif
};




The Process
A process is a program (object code stored on some media) in the midst of execution.
Processes are, however, more than just the executing program code (often called the text
section in Unix).They also include a set of resources such as open files and pending signals,
internal kernel data, processor state, a memory address space with one or more memory
mappings, one or more threads of execution, and a data section containing global variables.
Processes, in effect, are the living result of running program code.The kernel needs to
manage all these details efficiently and transparently.
Threads of execution, often shortened to threads, are the objects of activity within the
process. Each thread includes a unique program counter, process stack, and set of proces-
sor registers.The kernel schedules individual threads, not processes. In traditional Unix
systems, each process consists of one thread. In modern systems, however, multithreaded
programs—those that consist of more than one thread—are common.As you will see
later, Linux has a unique implementation of threads: It does not differentiate between
threads and processes.To Linux, a thread is just a special kind of process.
On modern operating systems, processes provide two virtualizations: a virtualized
processor and virtual memory.The virtual processor gives the process the illusion that it
alone monopolizes the system, despite possibly sharing the processor among hundreds of
other processes. Chapter 4,“Process Scheduling,” discusses this virtualization.Virtual
memory lets the process allocate and manage memory as if it alone owned all the mem-
ory in the system.Virtual memory is covered in Chapter 12,“Memory Management.”




